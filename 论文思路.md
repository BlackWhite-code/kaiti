## 思路

1. ##### 两篇论文的思路图

![image-20220928154456134](../AppData/Roaming/Typora/typora-user-images/image-20220928154456134.png)

元学习的贝叶斯的方法，用关系之间的关系图做图的先验知识，然后用已经标记的句子作为似然函数，得到我们的后验分布，这个后验分布我可以不可以直接用来进行处理，我只是用前面的这一部分。

![image-20220928154814173](../AppData/Roaming/Typora/typora-user-images/image-20220928154814173.png)

提示学习的方法，这个是自动找到标签词，提示学习的目的就是改变我们的数据，让数据来适合模型，让分类任务变成了生成任务，这个要看一下提示学习怎么搞的？按照我的理解，生成的词，我们就完成了分类。

2. 自己的思路

用后验分布，最后分类用提示学习的方法，提示学习的模板，最后改进了提示学习



我的切入点一定是为了解决什么问题，然后提出一个比较成熟的方法，或者为了缓解什么问题，一般都是长尾问题，看论文，主要其实是看有啥缺点，也就是为啥要用你这个东西，一般来说就是要看相关的方法，他的优点是什么，然后就可以应用到其他的领域里，然后对于他说了什么缺点可以克服，这就是引言部分的作用

第一：方法存在缺陷，然后我们改进方法、例如：提示学习存在缺陷，我就可以利用缺陷来进行改进

第二：某一个问题需要改进，远程监督现在会有长尾问题，这个问题需要解决，这个问题可以用小样本来解决，可以提出一个思想来强化或者减弱这个问题

提示学习，元学习都是用来解决小样本的问题，然后现在就要解决一些问题，prompting提示的融合

现在基本上都实在给提示学习加东西



方向暂定小样本，特征工程，因为前人的工作做的多，所以可以提供灵感

基本上都是为了考虑全局关系信息

上下文关系考虑了，



第一个图上面的为啥要加全局图的信息，为什么不加入子图，这样是不是更好一点，或者小样本中嵌入



直接相加，就是重合，我认为是半个加半个，这样和他不一样，他是直接

没有考虑什么问题，或者就是丢失了什么信息，这样我给他加上，



全局和局部怎么嵌入，全局信息确实没有人搞，局部信息对比学习都搞得有，全局信息的引入有什么作用。

[CLS]和实体开头的隐藏信息之间的那个信息比较重要，是不是加的愈多是不是越好，直接使用[CLS]或者直接使用实体开头隐藏的信息之和，主要做的初始原型的工作，初始原型形成之后然后加上关系描述之类的信息，或者用网络信息来表示一下，这个就转向了BERT的研究，怎么更好的利用BERT中的信息，这样可以生成更好的初始原型，因为BERT中是含有上下文信息的，BERT下就可以直接来进行查询或者生成，作为提示学习的模板，然后作为基本信息。



tokenization也叫做word segmentation，是一种操作，它按照特定需求，把文本切分成一个字符串序列（其元素一般称为token，或者叫词语）





论文发布于EMNLP 2022 10月

`<<Better Few-Shot Relation Extraction with Label Prompt Dropout>>`主要采用的是提示学习的方法，在下篇论文里会说文本标签（关系名称和关系描述）对于学习表示的作用。

**总结：**

**现阶段元学习中原型网络的研究现状：现在研究的方向就是怎么在学习过程中利用这些标签信息。有很多用图形网络，对比学习，注意力机制，直接相加，用校正的方法，现阶段最好的是校正的方法，基于预训练的方法还探讨了怎么来更好的表示一个语句信息和关系表示，MTB和CP两篇论文从实验上证明了关系抽取中利用实体前的隐藏状态拼接对于关系表示来说比较有效，还有对于关系抽取，上下文和实体**



问题：现在很多的作品都是在假设这种文本标签在学习和预测过程中始终存在，但是作者认为这种方法不一定总能获得最佳的结果。相反提出了一种称为标签提示丢失的新方法，它在学习过程中随机删除标签描述。

本文认为：向所有支持实例注入文本标签可能会使训练任务变得不具有挑战性，因为模型在训练过程中可能很大程度上依赖文本标签。在测试集过程中，当面对不可见的关系和文本标签时，会导致较差的性能，理想情况下，文本标签应该被视为额外的信息源，以便模型可以使用或不使用文本标签。TODO：通俗来说就是让文本描述信息当做外部信息，可能增加了噪声，也可能增加了相关的信息。

本文提出一种**标签提示丢失方法(LPD)**的新方法：直接去拼接文本标签和上下文句子，并一起提供给Transformer编码器，文本标签用作标签提示，以引导和规范Transformer编译器通过自我关注输出标签感知关系表示。在训练过程中，我们随机丢弃提示标签以创建更具挑战性的场景，这样模型就必须学会使用和不适用关系描述。

问题：为什么不用BERT；为什么要让模型更具挑战性，随机抛弃一些提示标签。

本文还提出了一个问题：其中预训练数据包含的关系类型实际上与测试集中的关系类型重叠。本文认为，这可能不是一个适合少数人学习的理想设置，并表明现有的努力的绩效提高可能部分归因于“知识泄露”问题。本文建议过滤掉了预训练数据中的所有重叠关系类型，并进行严格的小样本评估。

问题：也是小样本训练和测试的步骤不清晰。针对这个问题，它自己定了一个标准，然后都拉到了一个标准来进行。

贡献有两个：LPD；确定了文献中先前试验设置的局限性，提出了更严格的FSRE评估设置，对于两个设置，模型改进。

LPD：基于提示的微调

提示学习方法也要看一下





本文主要是利用了提示学习方法，改进的提示学习，当然最后是生成更好的原型。

在本文中主要是用术语标签提示、关系描述和文本标签，

















过拟合，噪声，开题题目比较重要，最后要解决的问题

技术路线和开题报告









总结：

基于BERT的原型网络(Baldini Soares等人， 2019; Peng等人, 2020a)在FSRE上表现出令人深刻的性能，但类原型通过每个类的支持实例的平均表示来构建，忽略了可能提供额外有用信息的文本标签。

Yang et al. (2020) 向模型中插入实体类型信息和关系描述。

Dong et al. (2021) 使用关系编码器来生成句子编码器之外的关系表示。

Han et al. (2021a)提出了一种混合原型网络，可以从上下文句子和关系描述中生成混合原型。



所有的工作都是要解决噪声和过拟合问题，很多数据增强方面：对比学习，添加外部信息：MTB，CP，如果把关系描述是外部信息，利用了外部信息和对比学习，过拟合问题：MTB也是用了bank的方式来防止过拟合，这个方式在LPD方法里也使用了，里面具体来说就是MTB主要随机bank实体，LPD主要bank关系标签，和图像处理过程中比较像，随机来bank图像，也可以通过加正则项。最后的目的就是生成更好的原型向量，让原型向量来更好的表示这个类，然后出现更好的分类效果。小样本主要通过数据增强，降低过拟合来更好的利用数据。





问题：还是要弄明白小样本的试验流程，对于查询集来说是怎么操作的？整个原型网络怎么做的？

方向：可不可再[CLS]和实体前面的实体隐藏状态，用的做多的就是实体前面的隐藏状态拼接，平均得出的，MTB的方法中证明了实体前面隐藏的状态拼接效果最好的。分类方法可不可以直接用欧式空间不用点积方式。本来想着可不可以用提示学习方法来生成原型向量，但是上面已经有论文做过这个方面的工作。
